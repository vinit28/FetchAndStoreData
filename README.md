# FetchAndStoreData
Asked to replicate the work that we have done in class for the Citibike Web API, but for a different web source. Specifically, what I need to do:  Identify a web API that returns data that change over time. Pick a data source for which historic data are not readily and easily accessible. Some default options:  Twitter trending topics, NYTimes Top Stories together with Alchemy Entity extraction. Create a database and the corresponding set of tables for storing the data, following the paradigm of the Citibike example. You should model the database properly to allow for storing of the data that are changing over time. Our approach with the Citibike database where we used two tables should provide guidance for that. Write Python code that connects to the API, fetches the data, and stores the data in the database. Convert your code into a self-executable Python script and schedule it to run periodically using cron. You do not need to schedule the script to run too often. For example, for NY Times news stories and Twitter trending topics, fetching them every hour is more than sufficient.
